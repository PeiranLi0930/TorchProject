{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-18T20:02:55.544605Z",
     "start_time": "2023-06-18T20:02:55.540176Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils import *\n",
    "from data_setup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = device_check()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T20:02:55.898400Z",
     "start_time": "2023-06-18T20:02:55.881761Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(<torch.utils.data.dataloader.DataLoader at 0x158fd5360>,\n <torch.utils.data.dataloader.DataLoader at 0x159003d60>,\n ['pizza', 'steak', 'sushi'],\n {'pizza': 0, 'steak': 1, 'sushi': 2})"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "train_dir = \"./data/pizza_steak_sushi/train\"\n",
    "test_dir = \"./data/pizza_steak_sushi/test\"\n",
    "\n",
    "manual_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "train_dataloader, test_dataloader, classes, class_to_idx = create_dataloaders(train_dir,\n",
    "                                                                              test_dir,\n",
    "                                                                              manual_transform,\n",
    "                                                                              32, num_workers = 0)\n",
    "train_dataloader, test_dataloader, classes, class_to_idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T20:02:56.246780Z",
     "start_time": "2023-06-18T20:02:56.236740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(<torch.utils.data.dataloader.DataLoader at 0x12f7fdf60>,\n <torch.utils.data.dataloader.DataLoader at 0x158c8ee90>,\n ['pizza', 'steak', 'sushi'],\n {'pizza': 0, 'steak': 1, 'sushi': 2})"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "auto_trans = weights.transforms()\n",
    "\n",
    "train_dataloader, test_dataloader, classes, class_to_idx = create_dataloaders(train_dir,\n",
    "                                                                              test_dir,\n",
    "                                                                              auto_trans,\n",
    "                                                                              32,\n",
    "                                                                              num_workers = 0)\n",
    "\n",
    "train_dataloader, test_dataloader, classes, class_to_idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T20:02:56.750789Z",
     "start_time": "2023-06-18T20:02:56.745136Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "========================================================================================================================\nLayer (type (var_name))                                      Input Shape     Output Shape    Param #         Trainable\n========================================================================================================================\nEfficientNet (EfficientNet)                                  [32, 3, 224, 224] [32, 3]         --              Partial\n├─Sequential (features)                                      [32, 3, 224, 224] [32, 1280, 7, 7] --              False\n│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224] [32, 32, 112, 112] --              False\n│    │    └─Conv2d (0)                                       [32, 3, 224, 224] [32, 32, 112, 112] (864)           False\n│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112] [32, 32, 112, 112] (64)            False\n│    │    └─SiLU (2)                                         [32, 32, 112, 112] [32, 32, 112, 112] --              --\n│    └─Sequential (1)                                        [32, 32, 112, 112] [32, 16, 112, 112] --              False\n│    │    └─MBConv (0)                                       [32, 32, 112, 112] [32, 16, 112, 112] (1,448)         False\n│    └─Sequential (2)                                        [32, 16, 112, 112] [32, 24, 56, 56] --              False\n│    │    └─MBConv (0)                                       [32, 16, 112, 112] [32, 24, 56, 56] (6,004)         False\n│    │    └─MBConv (1)                                       [32, 24, 56, 56] [32, 24, 56, 56] (10,710)        False\n│    └─Sequential (3)                                        [32, 24, 56, 56] [32, 40, 28, 28] --              False\n│    │    └─MBConv (0)                                       [32, 24, 56, 56] [32, 40, 28, 28] (15,350)        False\n│    │    └─MBConv (1)                                       [32, 40, 28, 28] [32, 40, 28, 28] (31,290)        False\n│    └─Sequential (4)                                        [32, 40, 28, 28] [32, 80, 14, 14] --              False\n│    │    └─MBConv (0)                                       [32, 40, 28, 28] [32, 80, 14, 14] (37,130)        False\n│    │    └─MBConv (1)                                       [32, 80, 14, 14] [32, 80, 14, 14] (102,900)       False\n│    │    └─MBConv (2)                                       [32, 80, 14, 14] [32, 80, 14, 14] (102,900)       False\n│    └─Sequential (5)                                        [32, 80, 14, 14] [32, 112, 14, 14] --              False\n│    │    └─MBConv (0)                                       [32, 80, 14, 14] [32, 112, 14, 14] (126,004)       False\n│    │    └─MBConv (1)                                       [32, 112, 14, 14] [32, 112, 14, 14] (208,572)       False\n│    │    └─MBConv (2)                                       [32, 112, 14, 14] [32, 112, 14, 14] (208,572)       False\n│    └─Sequential (6)                                        [32, 112, 14, 14] [32, 192, 7, 7] --              False\n│    │    └─MBConv (0)                                       [32, 112, 14, 14] [32, 192, 7, 7] (262,492)       False\n│    │    └─MBConv (1)                                       [32, 192, 7, 7] [32, 192, 7, 7] (587,952)       False\n│    │    └─MBConv (2)                                       [32, 192, 7, 7] [32, 192, 7, 7] (587,952)       False\n│    │    └─MBConv (3)                                       [32, 192, 7, 7] [32, 192, 7, 7] (587,952)       False\n│    └─Sequential (7)                                        [32, 192, 7, 7] [32, 320, 7, 7] --              False\n│    │    └─MBConv (0)                                       [32, 192, 7, 7] [32, 320, 7, 7] (717,232)       False\n│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7] [32, 1280, 7, 7] --              False\n│    │    └─Conv2d (0)                                       [32, 320, 7, 7] [32, 1280, 7, 7] (409,600)       False\n│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7] [32, 1280, 7, 7] (2,560)         False\n│    │    └─SiLU (2)                                         [32, 1280, 7, 7] [32, 1280, 7, 7] --              --\n├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7] [32, 1280, 1, 1] --              --\n├─Sequential (classifier)                                    [32, 1280]      [32, 3]         --              True\n│    └─Dropout (0)                                           [32, 1280]      [32, 1280]      --              --\n│    └─Linear (1)                                            [32, 1280]      [32, 3]         3,843           True\n========================================================================================================================\nTotal params: 4,011,391\nTrainable params: 3,843\nNon-trainable params: 4,007,548\nTotal mult-adds (G): 12.31\n========================================================================================================================\nInput size (MB): 19.27\nForward/backward pass size (MB): 3452.09\nParams size (MB): 16.05\nEstimated Total Size (MB): 3487.41\n========================================================================================================================"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b0(weights = weights).to(device)\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(nn.Dropout(p = 0.2, inplace = True),\n",
    "                                 nn.Linear(1280, 3)).to(device)\n",
    "\n",
    "summary(model, (32, 3, 224, 224), verbose = 0,\n",
    "        col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width = 15,\n",
    "        row_settings = [\"var_names\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T20:03:00.358935Z",
     "start_time": "2023-06-18T20:02:57.451933Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T20:03:00.363019Z",
     "start_time": "2023-06-18T20:03:00.360838Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T20:03:00.366860Z",
     "start_time": "2023-06-18T20:03:00.363875Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "def train(model: nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device\n",
    "          ):\n",
    "    results = {\"train_loss\": [], \"train_acc\":[], \"test_loss\":[], \"test_acc\":[]}\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, None, device)\n",
    "        test_loss, test_acc = test_step(model, test_dataloader, loss_fn, device)\n",
    "\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        writer.add_scalar(tag = \"Train Loss\", scalar_value = train_loss, global_step = epoch)\n",
    "        writer.add_scalar(tag = \"Test Loss\", scalar_value = test_loss, global_step = epoch)\n",
    "        writer.add_scalar(tag = \"Train Acc\", scalar_value = train_acc, global_step = epoch)\n",
    "        writer.add_scalar(tag = \"Test Acc\", scalar_value = test_acc, global_step = epoch)\n",
    "\n",
    "        writer.add_graph(model = model, input_to_model = torch.randn(32, 3, 224, 224).to(device))\n",
    "\n",
    "\n",
    "    writer.close()\n",
    "    return results\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T20:16:58.114444Z",
     "start_time": "2023-06-18T20:16:58.110276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4445122377b44539962f630fdadd30a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.6076 | train_acc: 0.8008 | test_loss: 0.5617 | test_acc: 0.8456\n",
      "Epoch: 2 | train_loss: 0.5412 | train_acc: 0.8086 | test_loss: 0.5609 | test_acc: 0.8759\n",
      "Epoch: 3 | train_loss: 0.5370 | train_acc: 0.8359 | test_loss: 0.5548 | test_acc: 0.8561\n"
     ]
    }
   ],
   "source": [
    "results = train(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs = 3, device\n",
    "= device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T20:19:05.774138Z",
     "start_time": "2023-06-18T20:16:58.850847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from utils import train_step, test_step\n",
    "\n",
    "\n",
    "def new_train(model: nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "               }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model = model,\n",
    "                                           dataloader = train_dataloader,\n",
    "                                           loss_fn = loss_fn,\n",
    "                                           optimizer = optimizer,\n",
    "                                           scheduler = None,\n",
    "                                           device = device)\n",
    "        test_loss, test_acc = test_step(model = model,\n",
    "                                        dataloader = test_dataloader,\n",
    "                                        loss_fn = loss_fn,\n",
    "                                        device = device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "                f\"Epoch: {epoch + 1} | \"\n",
    "                f\"train_loss: {train_loss:.4f} | \"\n",
    "                f\"train_acc: {train_acc:.4f} | \"\n",
    "                f\"test_loss: {test_loss:.4f} | \"\n",
    "                f\"test_acc: {test_acc:.4f}\"\n",
    "                )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        ### New: Experiment tracking ###\n",
    "        # Add loss results to SummaryWriter\n",
    "        writer.add_scalars(main_tag = \"Loss\",\n",
    "                           tag_scalar_dict = {\"train_loss\": train_loss,\n",
    "                                              \"test_loss\": test_loss},\n",
    "                           global_step = epoch)\n",
    "\n",
    "        # Add accuracy results to SummaryWriter\n",
    "        writer.add_scalars(main_tag = \"Accuracy\",\n",
    "                           tag_scalar_dict = {\"train_acc\": train_acc,\n",
    "                                              \"test_acc\": test_acc},\n",
    "                           global_step = epoch)\n",
    "\n",
    "        # Track the PyTorch model architecture\n",
    "        writer.add_graph(model = model,\n",
    "                         # Pass in an example input\n",
    "                         input_to_model = torch.randn(32, 3, 224, 224).to(device))\n",
    "\n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "\n",
    "    ### End new ###\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T01:44:11.656156Z",
     "start_time": "2023-06-17T01:44:11.654651Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f141e4a708d646848f63aeeeec7319a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <F0D48035-EF9E-3141-9F63-566920E60D7C> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7422C53A-9F13-3592-9338-E2EA7D46A90F> /Users/lipeiran/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mnew_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[13], line 20\u001B[0m, in \u001B[0;36mnew_train\u001B[0;34m(model, train_dataloader, test_dataloader, optimizer, loss_fn, epochs, device)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Loop through training and testing steps for a number of epochs\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(epochs)):\n\u001B[0;32m---> 20\u001B[0m     train_loss, train_acc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     test_loss, test_acc \u001B[38;5;241m=\u001B[39m test_step(model \u001B[38;5;241m=\u001B[39m model,\n\u001B[1;32m     27\u001B[0m                                     dataloader \u001B[38;5;241m=\u001B[39m test_dataloader,\n\u001B[1;32m     28\u001B[0m                                     loss_fn \u001B[38;5;241m=\u001B[39m loss_fn,\n\u001B[1;32m     29\u001B[0m                                     device \u001B[38;5;241m=\u001B[39m device)\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;66;03m# Print out what's happening\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/TorchProject/utils.py:101\u001B[0m, in \u001B[0;36mtrain_step\u001B[0;34m(model, dataloader, loss_fn, optimizer, scheduler, device)\u001B[0m\n\u001B[1;32m     98\u001B[0m X, y \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mto(device), y\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    100\u001B[0m \u001B[38;5;66;03m# 1. Forward pass\u001B[39;00m\n\u001B[0;32m--> 101\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m# 2. Calculate  and accumulate loss\u001B[39;00m\n\u001B[1;32m    104\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(y_pred, y)\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/models/efficientnet.py:355\u001B[0m, in \u001B[0;36mEfficientNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torchvision/models/efficientnet.py:345\u001B[0m, in \u001B[0;36mEfficientNet._forward_impl\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    344\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_forward_impl\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 345\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavgpool(x)\n\u001B[1;32m    348\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mflatten(x, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/TorchProject/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Input type (MPSFloatType) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "results = new_train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=5,\n",
    "                device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T01:44:53.771203Z",
     "start_time": "2023-06-17T01:44:11.662279Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
