{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Embedding an Input Sentence\n",
    "\n",
    "For simplicity, here our dictionary dc is restricted to the words that occur in the input sentence. In a real-world application, we would consider all words in the training dataset (typical vocabulary sizes range between 30k to 50k).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence  = \"Life is short, eat dessert first\"\n",
    "\n",
    "# Create Dictionary\n",
    "dict = {s : i for i, s in enumerate(sorted(sentence.replace(\",\", \"\").split()))}\n",
    "\n",
    "dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T17:57:31.163972Z",
     "start_time": "2023-06-29T17:57:31.161212Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assign the Index to Each Word"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 4, 5, 2, 1, 3])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "sentence_idx = torch.tensor([dict[s] for s in sentence.replace(',', '').split()])\n",
    "sentence_idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T18:01:34.498889Z",
     "start_time": "2023-06-29T18:01:33.690016Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word Embedding\n",
    "Here, we will use a 16-dimensional embedding such that each input word is represented by a 16-dimensional vector."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "embeder = torch.nn.Embedding(6, 16)\n",
    "embedded_sentence = embeder(sentence_idx).detach()\n",
    "\n",
    "\n",
    "print(embedded_sentence.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T18:04:16.660623Z",
     "start_time": "2023-06-29T18:04:16.627372Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Weight Matrices"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([24, 16]), torch.Size([24, 16]), torch.Size([28, 16]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "d = embedded_sentence.shape[1]\n",
    "\n",
    "d_q, d_k, d_v = 24, 24, 28\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.randn(d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.randn(d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.randn(d_v, d))\n",
    "\n",
    "W_query.shape, W_key.shape, W_value.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T18:39:51.904276Z",
     "start_time": "2023-06-29T18:39:51.893251Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Computing the Unnormalized Attention Weights\n",
    "We pick the second words $x^{(2)}$ as example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([24]), torch.Size([24]), torch.Size([28]))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "query_2 = W_query @ x_2\n",
    "key_2 = W_key @ x_2\n",
    "value_2 = W_value @ x_2\n",
    "\n",
    "query_2.shape, key_2.shape, value_2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T18:32:34.857706Z",
     "start_time": "2023-06-29T18:32:34.853013Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then generalize this to compute th remaining key, and value elements for all inputs as well, since we will need them in the next step when we compute the unnormalized attention weights ω:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([6, 24]), torch.Size([6, 28]))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = (W_key @ embedded_sentence.T).T\n",
    "values = (W_value @ embedded_sentence.T).T\n",
    "\n",
    "keys.shape, values.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T18:34:23.237904Z",
     "start_time": "2023-06-29T18:34:23.232098Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then generalize this to compute th remaining key, and value elements for all inputs as well, since we will need them in the next step when we compute the unnormalized attention weights ω\n",
    "\n",
    "As illustrated in the figure above, we compute $w_{ij}$\n",
    " as the dot product between the query and key sequences, $ω_{ij}=q^{(i)}^⊤k^{(j)}$\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-98.1709, grad_fn=<DotBackward0>)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the unnormalized attention weights for the query and 5th input word\n",
    "omega_24 = query_2.dot(keys[4])\n",
    "omega_24"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T18:44:07.066502Z",
     "start_time": "2023-06-29T18:44:07.049526Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([  83.1533,   95.5014, -100.8583,   63.5880,  -98.1709,    9.3997],\n        grad_fn=<SqueezeBackward3>),\n torch.Size([6]))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For all tokens\n",
    "omega_2 = query_2 @ keys.T\n",
    "omega_2, omega_2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T18:46:18.727666Z",
     "start_time": "2023-06-29T18:46:18.712331Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([7.4329e-02, 9.2430e-01, 3.6185e-18, 1.3699e-03, 6.2628e-18, 2.1523e-08],\n       grad_fn=<SoftmaxBackward0>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the\n",
    "import torch.nn.functional as F\n",
    "\n",
    "attention_weights_2 = F.softmax(omega_2 / d_k ** .5, dim = 0)\n",
    "attention_weights_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T18:55:35.660747Z",
     "start_time": "2023-06-29T18:55:35.655454Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([28])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector_2 = attention_weights_2 @ values\n",
    "\n",
    "context_vector_2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T19:42:13.014621Z",
     "start_time": "2023-06-29T19:42:13.008768Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "head = 3\n",
    "\n",
    "# (3, 24, 16)\n",
    "multihead_W_query = torch.nn.Parameter(torch.randn(head, d_q, d))\n",
    "multihead_W_key = torch.nn.Parameter(torch.randn(head, d_k, d))\n",
    "# (3, 28, 16)\n",
    "multihead_W_value = torch.nn.Parameter(torch.randn(head, d_v, d))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T19:50:25.733361Z",
     "start_time": "2023-06-29T19:50:25.730348Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# q, k, v for x_2\n",
    "multihead_query_2 = multihead_W_query @ x_2 # (3, 24)\n",
    "multihead_key_2 = multihead_W_key @ x_2 # (3, 24)\n",
    "multihead_value_2 = multihead_W_value @ x_2 # (3, 24)\n",
    "\n",
    "\n",
    "# x_2 asks each other words, then we need to calculate the k, v for other tokens\n",
    "# first, we need to expand the input sequence embeddings to the number of heads\n",
    "stacked_inputs = embedded_sentence.T.repeat(head, 1, 1) # (3, 16, 6)\n",
    "\n",
    "\n",
    "multihead_keys = torch.bmm(multihead_W_key, stacked_inputs)# (3, 24, 6)\n",
    "multihead_values = torch.bmm(multihead_W_value, stacked_inputs) # (3, 28, 6)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T20:08:08.893835Z",
     "start_time": "2023-06-29T20:08:08.884179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 6])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let x_2 asks every token -> unnormalized attention score\n",
    "multihead_query_2.unsqueeze(1)\n",
    "\n",
    "multihead_attention_unnormalized_score_2 =  torch.bmm(multihead_query_2.unsqueeze(dim = 1),\n",
    "                                                      multihead_keys).squeeze() # (3, 6)\n",
    "\n",
    "multihead_attention_normalized_score_2 = F.softmax(multihead_attention_unnormalized_score_2 / d_k\n",
    "                                                   ** 0.5, dim = 1) # (3, 6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T20:11:33.035618Z",
     "start_time": "2023-06-29T20:11:33.032119Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 28])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_context_score_2 = torch.bmm(multihead_attention_normalized_score_2.unsqueeze(1),\n",
    "                                      multihead_values.permute(0, 2, 1)).squeeze()  # (3, 28)\n",
    "multihead_context_score_2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-29T20:17:00.100346Z",
     "start_time": "2023-06-29T20:17:00.096019Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
